{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Crop Yield Prediction - ML Pipeline Notebook\n",
        "\n",
        "This notebook integrates data preprocessing, model training, and evaluation for crop yield prediction.\n",
        "\n",
        "**Objective**: Predict crop yield and recommend the most profitable crops based on environmental factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_merge_data(base_path='/home/lithium/P12/Crop Yield Prediction Dataset'):\n",
        "    \"\"\"\n",
        "    Loads raw CSV files, cleans them, and merges them into a single dataset.\n",
        "    \"\"\"\n",
        "    # Load Datasets\n",
        "    print(\"Loading datasets...\")\n",
        "    yield_df = pd.read_csv(os.path.join(base_path, \"yield.csv\"))\n",
        "    rain_df = pd.read_csv(os.path.join(base_path, \"rainfall.csv\"))\n",
        "    temp_df = pd.read_csv(os.path.join(base_path, \"temp.csv\"))\n",
        "    pest_df = pd.read_csv(os.path.join(base_path, \"pesticides.csv\"))\n",
        "\n",
        "    # --- Cleaning & Renaming ---\n",
        "    # 1. Yield Data\n",
        "    yield_df = yield_df[['Area', 'Item', 'Year', 'Value']].rename(columns={'Value': 'Yield_hg_ha'})\n",
        "\n",
        "    # 2. Rainfall Data\n",
        "    rain_df.columns = [col.strip() for col in rain_df.columns]\n",
        "    rain_df = rain_df.rename(columns={'average_rain_fall_mm_per_year': 'avg_rainfall_mm'})\n",
        "    rain_df['avg_rainfall_mm'] = pd.to_numeric(rain_df['avg_rainfall_mm'], errors='coerce')\n",
        "\n",
        "    # 3. Temperature Data\n",
        "    temp_df = temp_df.rename(columns={'year': 'Year', 'country': 'Area', 'avg_temp': 'avg_temp_c'})\n",
        "\n",
        "    # 4. Pesticides Data\n",
        "    pest_df = pest_df[['Area', 'Year', 'Value']].rename(columns={'Value': 'Pesticides_tonnes'})\n",
        "\n",
        "    # --- Merging ---\n",
        "    print(\"Merging datasets...\")\n",
        "    merged_df = pd.merge(yield_df, rain_df, on=['Area', 'Year'], how='inner')\n",
        "    merged_df = pd.merge(merged_df, pest_df, on=['Area', 'Year'], how='inner')\n",
        "    merged_df = pd.merge(merged_df, temp_df, on=['Area', 'Year'], how='inner')\n",
        "\n",
        "    # --- Final Cleaning ---\n",
        "    initial_len = len(merged_df)\n",
        "    merged_df = merged_df.dropna()\n",
        "    print(f\"Dropped {initial_len - len(merged_df)} rows with missing values.\")\n",
        "\n",
        "    print(f\"Final shape: {merged_df.shape}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(merged_df.head())\n",
        "    \n",
        "    return merged_df\n",
        "\n",
        "# Load data (adjust path if needed)\n",
        "df = load_and_merge_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display dataset info\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(f\"\\nDataset Statistics:\")\n",
        "print(df.describe())\n",
        "print(f\"\\nUnique crops: {df['Item'].nunique()}\")\n",
        "print(f\"Unique areas: {df['Area'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target\n",
        "X = df.drop(columns=['Yield_hg_ha', 'Year'])\n",
        "y = df['Yield_hg_ha']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n",
        "print(f\"\\nFeatures: {X_train.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define categorical and numerical features\n",
        "categorical_features = ['Area', 'Item']\n",
        "numerical_features = ['avg_rainfall_mm', 'avg_temp_c', 'Pesticides_tonnes']\n",
        "\n",
        "# Create preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "print(\"Preprocessor created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Custom Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_profitability(y_true, y_pred, pesticides):\n",
        "    \"\"\"\n",
        "    Custom metric: Profitability Proxy.\n",
        "    Assume Price per unit yield = 200\n",
        "    Assume Cost per unit pesticide = 10\n",
        "    Profit = (Yield * 200) - (Pesticides * 10)\n",
        "    \"\"\"\n",
        "    price = 200\n",
        "    cost = 10\n",
        "    actual_profit = (y_true * price) - (pesticides * cost)\n",
        "    pred_profit = (y_pred * price) - (pesticides * cost)\n",
        "    return np.mean(np.abs(actual_profit - pred_profit))\n",
        "\n",
        "print(\"Profitability metric defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training - Ridge Regression (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Ridge Regression (Baseline)...\")\n",
        "\n",
        "pipeline_ridge = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', Ridge())\n",
        "])\n",
        "\n",
        "param_grid_ridge = {'regressor__alpha': [0.1, 1.0, 10.0]}\n",
        "grid_ridge = GridSearchCV(pipeline_ridge, param_grid_ridge, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_ridge.fit(X_train, y_train)\n",
        "\n",
        "best_ridge = grid_ridge.best_estimator_\n",
        "print(f\"Best Ridge parameters: {grid_ridge.best_params_}\")\n",
        "\n",
        "y_pred_ridge = best_ridge.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
        "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "profit_error_ridge = calculate_profitability(y_test, y_pred_ridge, X_test['Pesticides_tonnes'].values)\n",
        "\n",
        "print(f\"\\nRidge Regression Metrics:\")\n",
        "print(f\"  RMSE: {rmse_ridge:.4f}\")\n",
        "print(f\"  MAE: {mae_ridge:.4f}\")\n",
        "print(f\"  R² Score: {r2_ridge:.4f}\")\n",
        "print(f\"  Profitability Error: {profit_error_ridge:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Training - Random Forest (Challenger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Random Forest (Challenger)...\")\n",
        "\n",
        "pipeline_rf = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid_rf = {\n",
        "    'regressor__n_estimators': [10, 20],\n",
        "    'regressor__max_depth': [5, 10]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=2, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "print(f\"Best Random Forest parameters: {grid_rf.best_params_}\")\n",
        "\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "profit_error_rf = calculate_profitability(y_test, y_pred_rf, X_test['Pesticides_tonnes'].values)\n",
        "\n",
        "print(f\"\\nRandom Forest Metrics:\")\n",
        "print(f\"  RMSE: {rmse_rf:.4f}\")\n",
        "print(f\"  MAE: {mae_rf:.4f}\")\n",
        "print(f\"  R² Score: {r2_rf:.4f}\")\n",
        "print(f\"  Profitability Error: {profit_error_rf:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare models\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': ['Ridge Regression', 'Random Forest'],\n",
        "    'RMSE': [rmse_ridge, rmse_rf],\n",
        "    'MAE': [mae_ridge, mae_rf],\n",
        "    'R² Score': [r2_ridge, r2_rf],\n",
        "    'Profitability Error': [profit_error_ridge, profit_error_rf]\n",
        "})\n",
        "\n",
        "print(\"\\n=== Model Comparison ===\")\n",
        "print(comparison.to_string(index=False))\n",
        "\n",
        "# Select best model\n",
        "best_model = best_rf if r2_rf > r2_ridge else best_ridge\n",
        "best_model_name = 'Random Forest' if r2_rf > r2_ridge else 'Ridge Regression'\n",
        "print(f\"\\n✓ Best Model Selected: {best_model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create models directory if it doesn't exist\n",
        "os.makedirs('/home/lithium/P12/models', exist_ok=True)\n",
        "\n",
        "# Save the best model\n",
        "model_path = '/home/lithium/P12/models/best_model.pkl'\n",
        "joblib.dump(best_model, model_path)\n",
        "print(f\"Best model saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Prediction Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Make a single prediction\n",
        "example_input = pd.DataFrame({\n",
        "    'Area': ['India'],\n",
        "    'Item': ['Maize'],\n",
        "    'avg_rainfall_mm': [1200.0],\n",
        "    'avg_temp_c': [25.0],\n",
        "    'Pesticides_tonnes': [100.0]\n",
        "})\n",
        "\n",
        "predicted_yield = best_model.predict(example_input)[0]\n",
        "print(f\"Example Prediction:\")\n",
        "print(f\"  Area: India\")\n",
        "print(f\"  Crop: Maize\")\n",
        "print(f\"  Rainfall: 1200 mm\")\n",
        "print(f\"  Temperature: 25°C\")\n",
        "print(f\"  Pesticides: 100 tonnes\")\n",
        "print(f\"  Predicted Yield: {predicted_yield:.2f} hg/ha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Crop Recommendations Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommend_crops(area, rainfall, temp, pesticides, model, data, top_n=3):\n",
        "    \"\"\"\n",
        "    Recommend top N most profitable crops for given environmental conditions.\n",
        "    \"\"\"\n",
        "    unique_crops = data['Item'].unique().tolist()\n",
        "    recommendations = []\n",
        "    \n",
        "    price = 200  # Assumed price per unit yield\n",
        "    cost = 10    # Assumed cost per unit pesticide\n",
        "    \n",
        "    for crop in unique_crops:\n",
        "        input_data = pd.DataFrame({\n",
        "            'Area': [area],\n",
        "            'Item': [crop],\n",
        "            'avg_rainfall_mm': [rainfall],\n",
        "            'avg_temp_c': [temp],\n",
        "            'Pesticides_tonnes': [pesticides]\n",
        "        })\n",
        "        \n",
        "        try:\n",
        "            predicted_yield = model.predict(input_data)[0]\n",
        "            profit = (predicted_yield * price) - (pesticides * cost)\n",
        "            recommendations.append({\n",
        "                'crop': crop,\n",
        "                'predicted_yield': predicted_yield,\n",
        "                'profitability': profit\n",
        "            })\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    # Sort by profitability\n",
        "    recommendations.sort(key=lambda x: x['profitability'], reverse=True)\n",
        "    return recommendations[:top_n]\n",
        "\n",
        "# Example recommendations\n",
        "recs = recommend_crops('India', 1200, 25, 100, best_model, df)\n",
        "print(\"\\nTop 3 Recommended Crops for India (Rainfall: 1200mm, Temp: 25°C, Pesticides: 100 tonnes):\")\n",
        "for i, rec in enumerate(recs, 1):\n",
        "    print(f\"  {i}. {rec['crop']}\")\n",
        "    print(f\"     Predicted Yield: {rec['predicted_yield']:.2f} hg/ha\")\n",
        "    print(f\"     Estimated Profitability: ${rec['profitability']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Feature Importance (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract feature importance from Random Forest\n",
        "if hasattr(best_rf.named_steps['regressor'], 'feature_importances_'):\n",
        "    # Get the feature names after preprocessing\n",
        "    # This is a simplified view; actual feature names depend on encoder output\n",
        "    print(\"\\nTop Features by Importance (Random Forest):\")\n",
        "    importances = best_rf.named_steps['regressor'].feature_importances_\n",
        "    top_indices = np.argsort(importances)[-5:][::-1]\n",
        "    for idx in top_indices:\n",
        "        print(f\"  Feature {idx}: {importances[idx]:.4f}\")\n",
        "else:\n",
        "    print(\"Feature importance not available for this model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. todo\n",
        "\n",
        "- Deploy the model using the FastAPI backend (`app.py`)\n",
        "- Launch the Streamlit frontend for interactive predictions\n",
        "- Integrate MLflow for comprehensive experiment tracking\n",
        "- Consider hyperparameter tuning for improved performance"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
